{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data={'c1': [1, 2, 2], 'c2': [3, 4, 1]})\n",
    "\n",
    "f1 = df.iloc[0, :]\n",
    "f2 = df.iloc[1, :]\n",
    "\n",
    "# compute the cosine similarity between the first 2 rows\n",
    "cosine_sim = 1 - spatial.distance.cosine(f1, f2)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data={'user': [1, 1, 2, 2], 'rating': [3, 4, 1, 2]})\n",
    "\n",
    "def normalize_ratings(df, rating_col=\"rating\", user_col=\"user\"):\n",
    "    groups = df.groupby(user_col)[rating_col]\n",
    "    # computes group-wise mean/std and auto broadcasts to individual groups\n",
    "    mean = groups.transform(np.mean)\n",
    "    std = groups.transform(np.std)\n",
    "    return (df[rating_col] - mean) / std\n",
    "\n",
    "df[\"rating_normalized\"] = normalize_ratings(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data={'user': [1, 1, 2, 2], 'rating': [10, 10, 10, 10], 't': pd.to_datetime([\"2019-01-01\", \"2019-01-02\", \"2019-01-03\", \"2019-01-04\"])})\n",
    "\n",
    "def cumsum_days(s, duration='D'):\n",
    "    return s.diff().astype('timedelta64[%s]' % duration).fillna(0).cumsum().values\n",
    "\n",
    "def decay_ratings(df, decay=1, rating_col=\"rating\", time_col=\"t\"):\n",
    "    weight = np.exp(-cumsum_days(df[time_col]) * decay)\n",
    "    return df[rating_col] * weight\n",
    "\n",
    "half_life_t = 1\n",
    "decay = np.log(2) / half_life_t\n",
    "df[\"rating_decayed\"] = decay_ratings(df, decay=decay)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "sc = pyspark.SparkContext('local[*]')\n",
    "\n",
    "n_iter = 10\n",
    "rank = 10\n",
    "l2_reg = 1\n",
    "\n",
    "als = ALS() \\\n",
    "    .setMaxIter(n_iter) \\\n",
    "    .setRank(rank) \\\n",
    "    .setRegParam(l2_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(train_data)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c39ce73b6d48f343ffd00681afb9b3f63104480cfaffe0ebb445fe41a6801158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('packt-repo-M2qY5kM-': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
